{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import inv\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "mnist = pd.read_csv('/home/oyku/Desktop/Oyku/Convex 10-725/train_mnist.csv')\n",
    "mnist = pd.DataFrame.as_matrix(mnist)\n",
    "\n",
    "mnist_shuffled = shuffle(mnist)\n",
    "\n",
    "print mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4132\n",
      "4684\n",
      "(8816, 785)\n",
      "(8816,)\n"
     ]
    }
   ],
   "source": [
    "label = mnist[:,0]\n",
    "data = mnist[:,1::]\n",
    "print np.sum((label == 0) + 0)\n",
    "print np.sum((label == 1) + 0)\n",
    "\n",
    "new_data = mnist[(label < 2), :]\n",
    "new_label = label[(label < 2)]\n",
    "print new_data.shape\n",
    "print new_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8816, 785)\n",
      "(8816, 1)\n"
     ]
    }
   ],
   "source": [
    "X = new_data\n",
    "y = new_label.reshape([new_label.shape[0], 1])\n",
    "y[y == 0] = -1\n",
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8816, 786)\n"
     ]
    }
   ],
   "source": [
    "#Centralize the data\n",
    "for i in xrange(X.shape[1]):\n",
    "    X[:,i] = X[:,i] - np.mean(X[:,i])\n",
    "X = np.append(X, np.ones([X.shape[0],1]), axis = 1)\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9324\n"
     ]
    }
   ],
   "source": [
    "print 6216 + 3108\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-61291baf2a39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Train and Validation sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3108\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3108\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "#Train and Validation sets\n",
    "train = X[0:6216,:]\n",
    "train_y = y[0:6216,:]\n",
    "\n",
    "train = X[6216:9324,:]\n",
    "train_y = y[6216:9324,:]\n",
    "\n",
    "train = X[9324:,:]\n",
    "train_y = y[0:6216,:]\n",
    "\n",
    "X, [X.shape[0]-2600, 3108, 3108], axis = 0)\n",
    "print train.shape\n",
    "print valid.shape\n",
    "print test.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model parameters\n",
    "n = X.shape[0] #number of examples in train\n",
    "d = X.shape[1] #number of features in train\n",
    "\n",
    "C = 10\n",
    "epsilon = 0.5\n",
    "t = 5\n",
    "\n",
    "beta = 0.9 #backtracking step decrease rate\n",
    "t_mu = 1.2 #scaling factor of t for the barrier method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w and xi initialized according to constraints\n"
     ]
    }
   ],
   "source": [
    "w = np.random.rand(1,d)*1e-5\n",
    "xi = np.ones([n,1])\n",
    "while np.sum((y*(w.dot(X.T).T) >= epsilon - xi) + 0) < n:\n",
    "    xi = np.ones([n,1])\n",
    "    w = np.random.rand(1,d)*1e-5\n",
    "print \"w and xi initialized according to constraints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 25\n",
    "loss = np.zeros([1,epoch])\n",
    "accuracy = np.zeros([1,epoch])\n",
    "for e in xrange(epoch):\n",
    "    step = 1\n",
    "    \n",
    "    #gradients\n",
    "    denom = y*(w.dot(X.T).T) - epsilon + xi\n",
    "    dw = t*w - np.sum(1/(1.0*denom)* y.T.dot(X), 0)\n",
    "    dxi = t*C - 1/(1.0*denom) - 1/(1.0*xi)\n",
    "    dw /= n\n",
    "    dxi /= n\n",
    "\n",
    "    #gradient descent\n",
    "    temp_w = w - step*dw\n",
    "    temp_xi = xi - step*dxi\n",
    "\n",
    "    count = 0\n",
    "    #while constraints are not obeyed\n",
    "    while np.sum((y*(temp_w.dot(X.T).T) >= epsilon - temp_xi) + 0) + np.sum((temp_xi >= 0) + 0) < 2*n: \n",
    "        step = step*beta\n",
    "        temp_w = w - step*dw\n",
    "        temp_xi = xi - step*dxi\n",
    "        count += 1\n",
    "    print \"COUNT :\", count\n",
    "    denom_left = y*(temp_w.dot(X.T).T) - epsilon + temp_xi\n",
    "\n",
    "\n",
    "    loss_right = t * (0.5*w[:,0:-1].dot(w[:,0:-1].T) + C * np.sum(xi))\n",
    "    loss_right -= np.sum(np.log(denom)) + np.sum(np.log(xi)) #barrier method\n",
    "    loss_right /= n\n",
    "\n",
    "    loss_left = t * (0.5*temp_w[:,0:-1].dot(temp_w[:,0:-1].T) + C * np.sum(temp_xi))\n",
    "    loss_left -= np.sum(np.log(denom_left)) + np.sum(np.log(temp_xi)) \n",
    "    loss_left /= n\n",
    "\n",
    "    #Backtracking\n",
    "    count1 = 0\n",
    "    do = 0\n",
    "    while do == 0:\n",
    "        step = beta*step\n",
    "        temp_w = w - step*dw\n",
    "        temp_xi = xi - step*dxi\n",
    "\n",
    "        loss_right = t * (0.5*w[:,0:-1].dot(w[:,0:-1].T) + C * np.sum(xi))\n",
    "        loss_right -= np.sum(np.log(denom)) + np.sum(np.log(xi)) #barrier method\n",
    "        loss_right /= n\n",
    "\n",
    "        loss_left = t * (0.5*temp_w[:,0:-1].dot(temp_w[:,0:-1].T) + C * np.sum(temp_xi))\n",
    "        loss_left -= np.sum(np.log(denom_left)) + np.sum(np.log(temp_xi)) \n",
    "        loss_left /= n\n",
    "        count1 += 1\n",
    "        \n",
    "        if loss_left <= loss_right:\n",
    "            do = 1\n",
    "        if count1 > 500:\n",
    "            do = 1\n",
    "    print \"COUNT 1 :\", count1\n",
    "    loss[:,e] = loss_left\n",
    "    #finalize the gradient update\n",
    "    w = temp_w\n",
    "    xi = temp_xi\n",
    "\n",
    "    #end of Backtracking\n",
    "\n",
    "\n",
    "    t = t*t_mu\n",
    "    \n",
    "\n",
    "    predicted = (w.dot(X.T).T > 0) + 0\n",
    "    predicted[predicted == 0] = -1\n",
    "    accuracy[:,e] = np.sum((predicted - y == 0) + 0)/(1.0*n)*100\n",
    "    print \"-------- \", e, \" --------\"\n",
    "    print \"Learning rate from backtracking: \", step\n",
    "    print \"Loss: \", loss[:,e]\n",
    "    print \"Prediction accuracy: \",accuracy[:,e]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print loss[:,-1]\n",
    "print accuracy[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step = 1\n",
    "\n",
    "epoch = 20\n",
    "loss = np.zeros([1,epoch])\n",
    "accuracy = np.zeros([1,epoch])\n",
    "for e in xrange(epoch):\n",
    "    denom = y*(w.dot(X.T).T) - epsilon + xi\n",
    "\n",
    "    #gradients\n",
    "    dw = t*w - np.sum(1/(1.0*denom)* y.T.dot(X), 0)\n",
    "    dxi = t*C - 1/(1.0*denom) - 1/(1.0*xi)\n",
    "    dw /= n\n",
    "    dxi /= n\n",
    "\n",
    "    #gradient descent\n",
    "    w_left = w - step*dw\n",
    "    xi_left = xi - step*dxi\n",
    "    \n",
    "    #f_left = t *(0.5*w[:,0:-1].dot(w[:,0:-1].T) + C * np.sum(xi)) \n",
    "\n",
    "    loss[:,e] = t * (0.5*w[:,0:-1].dot(w[:,0:-1].T) + C * np.sum(xi))\n",
    "    loss[:,e] -= np.sum(np.log(denom)) + np.sum(np.log(xi)) #barrier method\n",
    "    loss[:,e] /= n\n",
    "    \n",
    "\n",
    "    predicted = (w.dot(X.T).T > 0) + 0\n",
    "    predicted[predicted == 0] = -1\n",
    "    accuracy[:,e] = np.sum((predicted - y == 0) + 0)/(1.0*n)*100\n",
    "    print \"-------- \", e, \" --------\"\n",
    "    print \"Loss: \", loss[:,e]\n",
    "    print \"Prediction accuracy: \",accuracy[:,e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
