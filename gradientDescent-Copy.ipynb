{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import inv\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "mnist = pd.read_csv('/home/oyku/Desktop/Oyku/Convex 10-725/train_mnist.csv')\n",
    "\n",
    "mnist = pd.DataFrame.as_matrix(mnist)\n",
    "\n",
    "mnist_shuffled = shuffle(mnist)\n",
    "\n",
    "print mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QeSIvxAUoQfSOr/AXwI8HkXPgzhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc9b1e9d910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = plt.imshow(mnist[0,1::].reshape([28,28]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "4132\n",
      "4684\n",
      "(8816, 784)\n",
      "(8816,)\n"
     ]
    }
   ],
   "source": [
    "label = mnist[:,0]\n",
    "data = mnist[:,1::]\n",
    "print data.shape\n",
    "print np.sum((label == 0) + 0)\n",
    "print np.sum((label == 1) + 0)\n",
    "\n",
    "new_data = data[(label < 2), :]\n",
    "new_label = label[(label < 2)]\n",
    "print new_data.shape\n",
    "print new_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8816, 784)\n",
      "(8816, 1)\n"
     ]
    }
   ],
   "source": [
    "X = new_data\n",
    "y = new_label.reshape([new_label.shape[0], 1])\n",
    "y[y == 0] = -1\n",
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8816, 785)\n"
     ]
    }
   ],
   "source": [
    "#Centralize the data\n",
    "for i in xrange(X.shape[1]):\n",
    "    X[:,i] = X[:,i] - np.mean(X[:,i])\n",
    "X = np.append(X, np.ones([X.shape[0],1]), axis = 1)\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhB/I1P8DaAhqL82ayL4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc9b1ed3550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = plt.imshow(X[0,0:-1].reshape([28,28]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6100, 785)\n",
      "(1358, 785)\n",
      "(1358, 785)\n"
     ]
    }
   ],
   "source": [
    "#Train and Validation sets\n",
    "train = X[0:6100,:]\n",
    "train_y = y[0:6100,:]\n",
    "\n",
    "valid = X[6100:7458,:]\n",
    "valid_y = y[6100:7458,:]\n",
    "\n",
    "test = X[7458:8816,:]\n",
    "test_y = y[7458:8816,:]\n",
    "\n",
    "print train.shape\n",
    "print valid.shape\n",
    "print test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model parameters\n",
    "n = train.shape[0] #number of examples in train\n",
    "d = train.shape[1] #number of features in train\n",
    "\n",
    "#C = 10\n",
    "# epsilon = 0.5\n",
    "# t = 5\n",
    "alpha = 0.5\n",
    "\n",
    "beta = 0.9 #backtracking step decrease rate\n",
    "#t_mu = 1.2 #scaling factor of t for the barrier method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.random.rand(1,d)*1e-3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gardient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- epoch:  e,  iteration:  0  ----------\n",
      "Loss:  [ 18.74863726]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  1  ----------\n",
      "Loss:  [ 16.30891199]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  2  ----------\n",
      "Loss:  [ 14.29934001]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  3  ----------\n",
      "Loss:  [ 12.59157595]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  4  ----------\n",
      "Loss:  [ 11.11775674]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  5  ----------\n",
      "Loss:  [ 9.8342663]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  6  ----------\n",
      "Loss:  [ 8.70997403]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  7  ----------\n",
      "Loss:  [ 7.72125673]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  8  ----------\n",
      "Loss:  [ 6.84942378]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  9  ----------\n",
      "Loss:  [ 6.07922377]\n",
      "Step:  1.90683748117e-06\n",
      "\n",
      "Validation accuracy:  [ 3.31369661]\n",
      "---------- epoch:  e,  iteration:  10  ----------\n",
      "Loss:  [ 5.3979209]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  11  ----------\n",
      "Loss:  [ 4.79469709]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  12  ----------\n",
      "Loss:  [ 4.26024888]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  13  ----------\n",
      "Loss:  [ 3.78650425]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  14  ----------\n",
      "Loss:  [ 3.36641553]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  15  ----------\n",
      "Loss:  [ 2.99380205]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  16  ----------\n",
      "Loss:  [ 2.66322641]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  17  ----------\n",
      "Loss:  [ 2.36989442]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  18  ----------\n",
      "Loss:  [ 2.10957216]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  19  ----------\n",
      "Loss:  [ 1.8785162]\n",
      "Step:  1.90683748117e-06\n",
      "\n",
      "Validation accuracy:  [ 6.40648012]\n",
      "---------- epoch:  e,  iteration:  20  ----------\n",
      "Loss:  [ 1.6734139]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  21  ----------\n",
      "Loss:  [ 1.49133199]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  22  ----------\n",
      "Loss:  [ 1.32967187]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  23  ----------\n",
      "Loss:  [ 1.18613054]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  24  ----------\n",
      "Loss:  [ 1.05866645]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  25  ----------\n",
      "Loss:  [ 0.94546931]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  26  ----------\n",
      "Loss:  [ 0.84493369]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  27  ----------\n",
      "Loss:  [ 0.75563556]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  28  ----------\n",
      "Loss:  [ 0.67631167]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  29  ----------\n",
      "Loss:  [ 0.60584127]\n",
      "Step:  1.90683748117e-06\n",
      "\n",
      "Validation accuracy:  [ 44.1826215]\n",
      "---------- epoch:  e,  iteration:  30  ----------\n",
      "Loss:  [ 0.54322995]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  31  ----------\n",
      "Loss:  [ 0.48759534]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  32  ----------\n",
      "Loss:  [ 0.43815441]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  33  ----------\n",
      "Loss:  [ 0.39421229]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  34  ----------\n",
      "Loss:  [ 0.35515227]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  35  ----------\n",
      "Loss:  [ 0.32042701]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  36  ----------\n",
      "Loss:  [ 0.2895507]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  37  ----------\n",
      "Loss:  [ 0.26209217]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  38  ----------\n",
      "Loss:  [ 0.23766866]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  39  ----------\n",
      "Loss:  [ 0.21594043]\n",
      "Step:  1.90683748117e-06\n",
      "\n",
      "Validation accuracy:  [ 92.19440353]\n",
      "---------- epoch:  e,  iteration:  40  ----------\n",
      "Loss:  [ 0.19660591]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  41  ----------\n",
      "Loss:  [ 0.17939738]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  42  ----------\n",
      "Loss:  [ 0.16407716]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  43  ----------\n",
      "Loss:  [ 0.15043429]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  44  ----------\n",
      "Loss:  [ 0.13828144]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  45  ----------\n",
      "Loss:  [ 0.12745232]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  46  ----------\n",
      "Loss:  [ 0.11779929]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  47  ----------\n",
      "Loss:  [ 0.10919126]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  48  ----------\n",
      "Loss:  [ 0.10151183]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  49  ----------\n",
      "Loss:  [ 0.09465765]\n",
      "Step:  1.90683748117e-06\n",
      "\n",
      "Validation accuracy:  [ 97.1281296]\n",
      "---------- epoch:  e,  iteration:  50  ----------\n",
      "Loss:  [ 0.08853697]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  51  ----------\n",
      "Loss:  [ 0.08306829]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  52  ----------\n",
      "Loss:  [ 0.07817925]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  53  ----------\n",
      "Loss:  [ 0.0738056]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  54  ----------\n",
      "Loss:  [ 0.06989025]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  55  ----------\n",
      "Loss:  [ 0.06638252]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  56  ----------\n",
      "Loss:  [ 0.0632374]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  57  ----------\n",
      "Loss:  [ 0.06041489]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  58  ----------\n",
      "Loss:  [ 0.05787949]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  59  ----------\n",
      "Loss:  [ 0.05559964]\n",
      "Step:  1.90683748117e-06\n",
      "\n",
      "Validation accuracy:  [ 98.30633284]\n",
      "---------- epoch:  e,  iteration:  60  ----------\n",
      "Loss:  [ 0.0535473]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  61  ----------\n",
      "Loss:  [ 0.05169758]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  62  ----------\n",
      "Loss:  [ 0.05002835]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  63  ----------\n",
      "Loss:  [ 0.04851994]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  64  ----------\n",
      "Loss:  [ 0.04715489]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  65  ----------\n",
      "Loss:  [ 0.04591766]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  66  ----------\n",
      "Loss:  [ 0.04479446]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  67  ----------\n",
      "Loss:  [ 0.04377301]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  68  ----------\n",
      "Loss:  [ 0.0428424]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  69  ----------\n",
      "Loss:  [ 0.04199294]\n",
      "Step:  1.90683748117e-06\n",
      "\n",
      "Validation accuracy:  [ 98.52724595]\n",
      "---------- epoch:  e,  iteration:  70  ----------\n",
      "Loss:  [ 0.04121601]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  71  ----------\n",
      "Loss:  [ 0.04050392]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  72  ----------\n",
      "Loss:  [ 0.03984986]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  73  ----------\n",
      "Loss:  [ 0.03924776]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  74  ----------\n",
      "Loss:  [ 0.03869221]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  75  ----------\n",
      "Loss:  [ 0.0381784]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  76  ----------\n",
      "Loss:  [ 0.03770206]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  77  ----------\n",
      "Loss:  [ 0.03725937]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  78  ----------\n",
      "Loss:  [ 0.03684693]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  79  ----------\n",
      "Loss:  [ 0.03646173]\n",
      "Step:  1.90683748117e-06\n",
      "\n",
      "Validation accuracy:  [ 98.96907216]\n",
      "---------- epoch:  e,  iteration:  80  ----------\n",
      "Loss:  [ 0.03610106]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  81  ----------\n",
      "Loss:  [ 0.03576252]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  82  ----------\n",
      "Loss:  [ 0.03544397]\n",
      "Step:  1.90683748117e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- epoch:  e,  iteration:  83  ----------\n",
      "Loss:  [ 0.03514349]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  84  ----------\n",
      "Loss:  [ 0.03485939]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  85  ----------\n",
      "Loss:  [ 0.03459013]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  86  ----------\n",
      "Loss:  [ 0.03433436]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  87  ----------\n",
      "Loss:  [ 0.03409085]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  88  ----------\n",
      "Loss:  [ 0.03408725]\n",
      "Step:  2.11870831241e-06\n",
      "---------- epoch:  e,  iteration:  89  ----------\n",
      "Loss:  [ 0.03383768]\n",
      "Step:  1.90683748117e-06\n",
      "\n",
      "Validation accuracy:  [ 99.11634757]\n",
      "---------- epoch:  e,  iteration:  90  ----------\n",
      "Loss:  [ 0.03360056]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  91  ----------\n",
      "Loss:  [ 0.03337476]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  92  ----------\n",
      "Loss:  [ 0.03337406]\n",
      "Step:  2.11870831241e-06\n",
      "---------- epoch:  e,  iteration:  93  ----------\n",
      "Loss:  [ 0.0331422]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  94  ----------\n",
      "Loss:  [ 0.03292186]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  95  ----------\n",
      "Loss:  [ 0.03271197]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  96  ----------\n",
      "Loss:  [ 0.03271326]\n",
      "Step:  2.11870831241e-06\n",
      "---------- epoch:  e,  iteration:  97  ----------\n",
      "Loss:  [ 0.03249738]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  98  ----------\n",
      "Loss:  [ 0.03229217]\n",
      "Step:  1.90683748117e-06\n",
      "---------- epoch:  e,  iteration:  99  ----------\n",
      "Loss:  [ 0.03209664]\n",
      "Step:  1.90683748117e-06\n",
      "\n",
      "Validation accuracy:  [ 99.04270987]\n"
     ]
    }
   ],
   "source": [
    "w = initial_w[:,:]\n",
    "\n",
    "runs = 10\n",
    "epoch = 10\n",
    "loss_store = np.zeros([1,runs*epoch])\n",
    "accuracy = np.zeros([1,epoch])\n",
    "\n",
    "\n",
    "count = 0\n",
    "for e in xrange(epoch):\n",
    "    for r in xrange(runs):\n",
    "        step = 1\n",
    "\n",
    "        dw = -(train_y.T - w.dot(train.T)).dot(train)\n",
    "        dw /= n\n",
    "\n",
    "        #Backtracking\n",
    "        temp_w = w - step*dw\n",
    "\n",
    "        loss = 0.5*(train_y.T - w.dot(train.T)).dot(train_y - w.dot(train.T).T)\n",
    "        loss_right = loss + step*alpha*loss.T.dot(loss)\n",
    "        loss_right /= n\n",
    "        loss_left = 0.5*(train_y.T - temp_w.dot(train.T)).dot(train_y - temp_w.dot(train.T).T)\n",
    "        loss_left /= n\n",
    "\n",
    "        while loss_left > loss_right:\n",
    "            step = beta*step\n",
    "            temp_w = w - step*dw\n",
    "\n",
    "            loss = 0.5*(train_y.T - w.dot(train.T)).dot(train_y - w.dot(train.T).T)\n",
    "            loss_right = loss + step*alpha*loss.T.dot(loss)\n",
    "            loss_right /= n\n",
    "            loss_left = 0.5*(train_y.T - temp_w.dot(train.T)).dot(train_y - temp_w.dot(train.T).T)\n",
    "            loss_left /= n\n",
    "\n",
    "        w = temp_w\n",
    "\n",
    "        predict_valid = w.dot(valid.T).T\n",
    "        predicted = (predict_valid > 0) + 0\n",
    "        predicted[predicted == 0] = -1\n",
    "        loss_store[:,count] = loss_left\n",
    "        print \"---------- epoch: \", \"e,  iteration: \", count , \" ----------\"\n",
    "        print \"Loss: \", loss_store[:,count]\n",
    "        print \"Step: \", step\n",
    "        count += 1\n",
    "\n",
    "    accuracy[:,e] = np.sum((predicted == valid_y) + 0)/(1.0*valid_y.shape[0]) * 100\n",
    "    print\n",
    "    print \"Validation accuracy: \", accuracy[:,e]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.11634757\n"
     ]
    }
   ],
   "source": [
    "predict_test = w.dot(test.T).T\n",
    "predicted_test = (predict_test > 0) + 0\n",
    "predicted_test[predicted_test == 0] = -1\n",
    "accuracy_test = np.sum((predicted_test == test_y) + 0)/(1.0*test_y.shape[0]) * 100\n",
    "print accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc9b1de82d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy.T, label='MSE')\n",
    "plt.title('Accuracy' )\n",
    "plt.xlabel('epoch number')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.31369661   6.40648012  44.1826215   92.19440353  97.1281296\n",
      "   98.30633284  98.52724595  98.96907216  99.11634757  99.04270987]]\n"
     ]
    }
   ],
   "source": [
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordinate Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------  0  --------------\n",
      "Loss:  [ 4.37258233]\n",
      "--------------  1  --------------\n",
      "Loss:  [ 1.81063946]\n",
      "--------------  2  --------------\n",
      "Loss:  [ 1.24834914]\n",
      "--------------  3  --------------\n",
      "Loss:  [ 0.99728509]\n",
      "--------------  4  --------------\n",
      "Loss:  [ 0.82650704]\n",
      "\n",
      "Validation accuracy:  [ 78.12960236]\n",
      "--------------  0  --------------\n",
      "Loss:  [ 0.69594433]\n",
      "--------------  1  --------------\n",
      "Loss:  [ 0.59297954]\n",
      "--------------  2  --------------\n",
      "Loss:  [ 0.51062255]\n",
      "--------------  3  --------------\n",
      "Loss:  [ 0.4440662]\n",
      "--------------  4  --------------\n",
      "Loss:  [ 0.38980052]\n",
      "\n",
      "Validation accuracy:  [ 87.92341679]\n",
      "--------------  0  --------------\n",
      "Loss:  [ 0.34520044]\n",
      "--------------  1  --------------\n",
      "Loss:  [ 0.30827133]\n",
      "--------------  2  --------------\n",
      "Loss:  [ 0.27747835]\n",
      "--------------  3  --------------\n",
      "Loss:  [ 0.251628]\n",
      "--------------  4  --------------\n",
      "Loss:  [ 0.22978416]\n",
      "\n",
      "Validation accuracy:  [ 92.48895434]\n",
      "--------------  0  --------------\n",
      "Loss:  [ 0.21120712]\n",
      "--------------  1  --------------\n",
      "Loss:  [ 0.19530868]\n",
      "--------------  2  --------------\n",
      "Loss:  [ 0.18161851]\n",
      "--------------  3  --------------\n",
      "Loss:  [ 0.1697586]\n",
      "--------------  4  --------------\n",
      "Loss:  [ 0.15942369]\n",
      "\n",
      "Validation accuracy:  [ 94.84536082]\n",
      "--------------  0  --------------\n",
      "Loss:  [ 0.15036612]\n",
      "--------------  1  --------------\n",
      "Loss:  [ 0.1423841]\n",
      "--------------  2  --------------\n",
      "Loss:  [ 0.13531245]\n",
      "--------------  3  --------------\n",
      "Loss:  [ 0.12901536]\n",
      "--------------  4  --------------\n",
      "Loss:  [ 0.12338066]\n",
      "\n",
      "Validation accuracy:  [ 95.80265096]\n"
     ]
    }
   ],
   "source": [
    "w_c = initial_w[:,:]\n",
    "\n",
    "runs = 5\n",
    "epoch = 5\n",
    "\n",
    "loss_store = np.zeros([1,runs*epoch*w_c.shape[1]])\n",
    "accuracy_c = np.zeros([1,epoch])\n",
    "\n",
    "step = 1e-6\n",
    "count = 0\n",
    "for e in xrange(epoch):\n",
    "    for r in xrange(runs):\n",
    "        for i in xrange(w_c.shape[1]):\n",
    "\n",
    "            dw = -(train_y.T - w_c.dot(train.T)).dot(train)\n",
    "            dw /= n\n",
    "            \n",
    "            w_c[:,i] = w_c[:,i] - step*dw[:,i]\n",
    "            #Backtracking\n",
    "            \n",
    "            loss = 0.5*(train_y.T - w_c.dot(train.T)).dot(train_y - w_c.dot(train.T).T)\n",
    "            loss /= n\n",
    "            \n",
    "        predict_valid = w_c.dot(valid.T).T\n",
    "        predicted = (predict_valid > 0) + 0\n",
    "        predicted[predicted == 0] = -1\n",
    "        loss_store[:,count] = loss\n",
    "        print \"-------------- \", r, \" --------------\"\n",
    "        print \"Loss: \", loss_store[:,count]\n",
    "        count += 1\n",
    "\n",
    "    accuracy_c[:,e] = np.sum((predicted == valid_y) + 0)/(1.0*valid_y.shape[0]) * 100\n",
    "    print\n",
    "    print \"Validation accuracy: \", accuracy_c[:,e]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.9072164948\n"
     ]
    }
   ],
   "source": [
    "predict_test_c = w_c.dot(test.T).T\n",
    "predicted_test_c = (predict_test_c > 0) + 0\n",
    "predicted_test_c[predicted_test_c == 0] = -1\n",
    "accuracy_test_c = np.sum((predicted_test_c == test_y) + 0)/(1.0*test_y.shape[0]) * 100\n",
    "print accuracy_test_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
